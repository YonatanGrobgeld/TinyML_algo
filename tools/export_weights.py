#!/usr/bin/env python3
"""
Export trained TinyFormer encoder weights to C int8_t arrays for litex_port/tinyformer.c.

Hyperparameters (fixed by C):
  S   = 16
  D   = 32
  FFN = 64
  H   = 1 (single head, d_head = D)

Expected PyTorch checkpoint (state_dict or {"state_dict": ...}) keys:
  W_q   [D, D]
  W_k   [D, D]
  W_v   [D, D]
  W_o   [D, D]
  W_ff1 [FFN, D] or [D, FFN]
  W_ff2 [D, FFN] or [FFN, D]
  b_q, b_k, b_v, b_o [D]
  b_ff1 [FFN]
  b_ff2 [D]

All weights/biases are quantized to signed int8 with clipping to [-127, 127]
and written as:

  litex_port/trained_weights.h
  litex_port/trained_weights.c

Usage (from repo root TinyML_algo/):
  python3 tools/export_weights.py --checkpoint path/to/state_dict.pt --output-dir litex_port
"""

import argparse
from pathlib import Path

import torch

S = 16
D = 32
FFN = 64


def quantize_to_int8(t: torch.Tensor) -> torch.Tensor:
    """Quantize to int8 with symmetric clipping to [-127, 127]."""
    t = t.to(torch.float32)
    t = torch.clamp(torch.round(t), -127.0, 127.0)
    return t.to(torch.int8)


def ensure_shape(name: str, tensor: torch.Tensor, expected_shapes):
    """Check tensor has one of the expected shapes."""
    shape = tuple(tensor.shape)
    for opt in expected_shapes:
        if shape == opt:
            return tensor, opt
    raise ValueError(f"{name}: unexpected shape {shape}, expected one of {expected_shapes}")


def maybe_transpose_ffn(name: str, tensor: torch.Tensor, target_shape):
    """
    For FFN weights, accept either target_shape or its transpose.
    E.g., target_shape=(FFN, D) allows (FFN, D) or (D, FFN).
    """
    tensor = tensor.detach().clone()
    current = tuple(tensor.shape)
    if current == target_shape:
        return tensor
    if len(current) == 2 and current[::-1] == target_shape:
        return tensor.t()
    raise ValueError(f"{name}: cannot reshape {current} to {target_shape} or its transpose")


def tensor_to_c_array(name: str, tensor: torch.Tensor, indent: str = "    ") -> str:
    """Render 1D or 2D int8 tensor as a C initializer."""
    if tensor.dtype != torch.int8:
        raise ValueError(f"{name}: expected int8 tensor, got {tensor.dtype}")

    if tensor.dim() == 1:
        vals = ", ".join(str(int(v)) for v in tensor.view(-1))
        return f"{{ {vals} }}"

    if tensor.dim() == 2:
        rows = []
        for row in tensor:
            vals = ", ".join(str(int(v)) for v in row.view(-1))
            rows.append(f"{indent}{{ {vals} }}")
        return "{\n" + ",\n".join(rows) + "\n}"

    raise ValueError(f"{name}: expected 1D or 2D tensor, got {tensor.dim()}D")


def write_header(path: Path) -> None:
    guard = "TRAINED_WEIGHTS_H"
    with path.open("w") as f:
        f.write(
            f"#ifndef {guard}\n"
            f"#define {guard}\n\n"
            f'#include "tinyformer.h"\n\n'
            f"// Trained TinyFormer encoder weights (generated by tools/export_weights.py)\n\n"
            f"extern const int8_t W_q[TINYFORMER_D][TINYFORMER_D];\n"
            f"extern const int8_t W_k[TINYFORMER_D][TINYFORMER_D];\n"
            f"extern const int8_t W_v[TINYFORMER_D][TINYFORMER_D];\n"
            f"extern const int8_t W_o[TINYFORMER_D][TINYFORMER_D];\n\n"
            f"extern const int8_t W_ff1[TINYFORMER_FFN][TINYFORMER_D];\n"
            f"extern const int8_t W_ff2[TINYFORMER_D][TINYFORMER_FFN];\n\n"
            f"extern const int8_t b_q[TINYFORMER_D];\n"
            f"extern const int8_t b_k[TINYFORMER_D];\n"
            f"extern const int8_t b_v[TINYFORMER_D];\n"
            f"extern const int8_t b_o[TINYFORMER_D];\n\n"
            f"extern const int8_t b_ff1[TINYFORMER_FFN];\n"
            f"extern const int8_t b_ff2[TINYFORMER_D];\n\n"
            f"#endif // {guard}\n"
        )


def write_source(path: Path, weights: dict) -> None:
    with path.open("w") as f:
        f.write(
            '// Trained TinyFormer encoder weights (generated by tools/export_weights.py)\n\n'
            '#include "tinyformer.h"\n'
            '#include "trained_weights.h"\n\n'
        )

        # Projections
        for name in ("W_q", "W_k", "W_v", "W_o"):
            t = weights[name]
            f.write(f"const int8_t {name}[TINYFORMER_D][TINYFORMER_D] = ")
            f.write(tensor_to_c_array(name, t, indent="    "))
            f.write(";\n\n")

        # FFN
        f.write("const int8_t W_ff1[TINYFORMER_FFN][TINYFORMER_D] = ")
        f.write(tensor_to_c_array("W_ff1", weights["W_ff1"], indent="    "))
        f.write(";\n\n")

        f.write("const int8_t W_ff2[TINYFORMER_D][TINYFORMER_FFN] = ")
        f.write(tensor_to_c_array("W_ff2", weights["W_ff2"], indent="    "))
        f.write(";\n\n")

        # Biases
        for name, macro in (
            ("b_q", "TINYFORMER_D"),
            ("b_k", "TINYFORMER_D"),
            ("b_v", "TINYFORMER_D"),
            ("b_o", "TINYFORMER_D"),
            ("b_ff1", "TINYFORMER_FFN"),
            ("b_ff2", "TINYFORMER_D"),
        ):
            t = weights[name]
            f.write(f"const int8_t {name}[{macro}] = ")
            f.write(tensor_to_c_array(name, t, indent="    "))
            f.write(";\n\n")


def main() -> None:
    parser = argparse.ArgumentParser(description="Export TinyFormer weights to C int8_t arrays.")
    parser.add_argument("--checkpoint", type=str, required=True, help="Path to PyTorch .pt checkpoint.")
    parser.add_argument(
        "--output-dir",
        type=str,
        default="litex_port",
        help="Directory for trained_weights.h/.c (default: litex_port).",
    )
    args = parser.parse_args()

    ckpt_path = Path(args.checkpoint)
    out_dir = Path(args.output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    state = torch.load(ckpt_path, map_location="cpu")
    if isinstance(state, dict) and "state_dict" in state:
        state_dict = state["state_dict"]
    else:
        state_dict = state

    required = [
        "W_q",
        "W_k",
        "W_v",
        "W_o",
        "W_ff1",
        "W_ff2",
        "b_q",
        "b_k",
        "b_v",
        "b_o",
        "b_ff1",
        "b_ff2",
    ]
    missing = [k for k in required if k not in state_dict]
    if missing:
        raise KeyError(f"Missing keys in checkpoint state_dict: {missing}")

    W_q = state_dict["W_q"].detach().cpu()
    W_k = state_dict["W_k"].detach().cpu()
    W_v = state_dict["W_v"].detach().cpu()
    W_o = state_dict["W_o"].detach().cpu()
    W_ff1 = state_dict["W_ff1"].detach().cpu()
    W_ff2 = state_dict["W_ff2"].detach().cpu()

    b_q = state_dict["b_q"].detach().cpu().view(-1)
    b_k = state_dict["b_k"].detach().cpu().view(-1)
    b_v = state_dict["b_v"].detach().cpu().view(-1)
    b_o = state_dict["b_o"].detach().cpu().view(-1)
    b_ff1 = state_dict["b_ff1"].detach().cpu().view(-1)
    b_ff2 = state_dict["b_ff2"].detach().cpu().view(-1)

    # Projections must be [D, D]
    for name, t in (("W_q", W_q), ("W_k", W_k), ("W_v", W_v), ("W_o", W_o)):
        t, _ = ensure_shape(name, t, [(D, D)])
        locals()[name] = t  # not strictly needed, but keeps names consistent

    # FFN: normalize to W_ff1[FFN,D], W_ff2[D,FFN]
    W_ff1 = maybe_transpose_ffn("W_ff1", W_ff1, (FFN, D))
    W_ff2 = maybe_transpose_ffn("W_ff2", W_ff2, (D, FFN))

    # Bias shapes
    b_q, _ = ensure_shape("b_q", b_q, [(D,)])
    b_k, _ = ensure_shape("b_k", b_k, [(D,)])
    b_v, _ = ensure_shape("b_v", b_v, [(D,)])
    b_o, _ = ensure_shape("b_o", b_o, [(D,)])
    b_ff1, _ = ensure_shape("b_ff1", b_ff1, [(FFN,)])
    b_ff2, _ = ensure_shape("b_ff2", b_ff2, [(D,)])

    weights = {
        "W_q": quantize_to_int8(W_q),
        "W_k": quantize_to_int8(W_k),
        "W_v": quantize_to_int8(W_v),
        "W_o": quantize_to_int8(W_o),
        "W_ff1": quantize_to_int8(W_ff1),
        "W_ff2": quantize_to_int8(W_ff2),
        "b_q": quantize_to_int8(b_q),
        "b_k": quantize_to_int8(b_k),
        "b_v": quantize_to_int8(b_v),
        "b_o": quantize_to_int8(b_o),
        "b_ff1": quantize_to_int8(b_ff1),
        "b_ff2": quantize_to_int8(b_ff2),
    }

    write_header(out_dir / "trained_weights.h")
    write_source(out_dir / "trained_weights.c", weights)

    print(f"Exported trained weights to {out_dir/'trained_weights.h'} and {out_dir/'trained_weights.c'}")


if __name__ == "__main__":
    main()

